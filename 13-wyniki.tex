\newpage
\section{Wyniki oraz napotkane problemy}

Parametry modelu:
\begin{itemize}
	  \item liczba neuronów warstw ukrytych - $100$
	  \item liczba warstw - $2$
	  \item liczba głowic - $100$
	  \item rozmiar batcha - $40$
	  \item czas uczenia - $40$h
	  \item współczynnik uczenia - $0.004$
	  \item liczba kroków czasowych - $50$
	\end{itemize}

Skuteczność wyniosła $15\%$. Nie udało nam się otrzymać wyników zbliżonych do tych osiągniętych podczas konkursu PAN. Sprawdziła się
część elementów z analizy ryzyka, które przewidywaliśmy.

\subsection{Problemy}
\subsubsection{Małe doświadczenie w dziedzinie konstruowania sieci neuronowych}
Było to dla nas pierwsze doświadczenie z sieciami neuronowymi, dlatego znaczną ilość czasu poświęciliśmy na
zrozumienie tego zagadnienia. Aby zrozumieć samą ideę zaczęliśmy od prostych modeli sieci typu feed forward,
następnie przeszliśmy do sieci rekurencyjnych. W całym procesie nauki musieliśmy zrozumieć,
wszystkie zagadnienia z nimi związane, jak entropia krzyżowa, softmax, propagacja w przód, propagacja wsteczna,
minimalizacja gradientu, itp.

\subsubsection{Długi czas uczenia}
Jedna epoka trwała od kilku do kilkunastu godzin w zależności od ilości danych, co znacząco spowalniało
prace nad usprawnieniem modelu.

\subsubsection{Znajomość biblioteki}
Zdobytą wiedzę i pomysł należało przełożyć na kod w Pythonie przy wykorzystaniu biblioteki Pytorch.
Problem który rozwiązywaliśmy był w jakimś stopniu niestandardowy, dlatego należało modyfikować
gotowe narzędzia i odpowiednio komponować z nich kod, często popełniane przy tym błędy prowadziły
do stopniowych zmian w kodzie, które oddzielone były długim czasem uczenia na sprawdzenie poprawek.

\subsubsection{Przeuczenie}
Ze względu na specyfikę problemu, którego cechą są bardzo krótkie teksty wejściowe bardzo poważnym
problemem jest przeuczenie sieci, która bardzo szybko uczy się tekstów treningowych na pamięć.

\subsubsection{Rosnąca wartość kosztu}
Doświadczyliśmy problemu z wartością kosztu, która najpierw stopniowo spadała, następnie gwałtownie wzrosła.
Nie udało nam się wyjaśnić czym była spowodowana. Zachowanie tego typu może wystąpić z wielu powodów - na przykład przy eksplozji gradientu,
spowodowanej przez przykładowo zbyt duży współczynnik uczenia. Jednak w naszym przypadku mieliśmy zastosowany
algorytm optymalizacji Adam, a także gradient kliping. Może być ono również spowodowane błędem w kodzie sieci.
\begin{figure}[H]
	\centering
	\includegraphics[height=7cm]{./images/exploading_gradient.png}
	\caption{Rosnąca wartość funkcji kosztu.}
	\label{fig:test5}
\end{figure}

\subsubsection{Różnice w długości tekstów}
Teksty z korpusu PAN 2015 \cite{pan} są bardzo krótkie, dodatkowo różnią się długością. Teksty te mają od 1500 do 2600 znaków, 1100 znaków
różnicy w tym przypadku to aż $43\%$ różnicy w długości. Teoretycznie głowica powinna uczyć się przewidywać znaki dla
swojego autora i podczas ewaluacji jego tekstów robić to lepiej od pozostałych głowic. Problemem jest
 jednak sytuacja wyżej opisana. Kiedy znaków jest tak mało
możliwa jest sytuacja w której głowica, której teksty są tymi najdłuższymi lepiej uczy się modelu języka od
pozostałych głowic więc skuteczniej przewiduje kolejne znaki dla wszystkich nieznanych teksów.

Popularne modele, które potrafią przewidywać kolejne słowa bądź litery szkolone są przykładowo na danych w postaci licznych
artykułów z \texttt{Wikipedii}, gdzie liczba danych do wyuczenia jest znacznie większa.

\newpage
\subsubsection{Błędy implementacyjne}
Błędy w implementacji sieci prowadziły do skrajnie złych wyników i znacznie opóźniały tempo pracy.
\begin{figure}[H]
	\centering
	\includegraphics[height=7cm]{./images/result1.png}
	\caption{Przykładowe dane z uczenia sieci błędnie zaimplementowanej.}
	\label{fig:test5}
	\end{figure}

\subsection{Wyniki eksperymentów i debugowanie sieci}
Niestety nie udało nam się otrzymać pozytywnych wyników. Został popełniony błąd w implementacji sieci,
którego bardzo długo nie udało nam się wykryć i rozwiązać, co bardzo opóźniło prace i nie pozwoliło na znalezienie
optymalnych parametrów uczenia. Efektem błędu było to, że sieć się nie uczyła, następnie kiedy zaczęła się
uczyć miała bardzo niską skuteczność na danych testowych. Głównym problemem był tu czas ewaluacji.
Debugowanie prowadziliśmy etapami, sprawdzając kolejne elementy sieci. Wyróżniliśmy następujące:

\subsubsection{Sprawdzenie modułu preprocesingu}
	Jest to najbardziej obszerny moduł. Podejrzewaliśmy, że problem może wynikać ze złego kodowania znaków,
	na przykład wszystkie znaki są zakodowane identycznie i stąd sieć się nie uczy. W tym celu odkodowywaliśmy
	zakodowane teksty i wyświetlaliśmy je na ekran. Jak się okazało teksty były zakodowane poprawnie, włączając w
	to redukcję alfabetu.

\subsubsection{Sprawdzenie modułu batchowania}
	  Jest to bardzo obszerny moduł, który czyta dane z tensorów zapisanych na dysku
	  i na ich podstawie generuje kolejne batche, podając kolejnych autorów w możliwie losowej kolejności, tak by sieć
	  nie uczyła się artefaktów. Generuje przy tym oczekiwane wyjście, które następnie jest wykorzystywane do
	  liczenia kosztu. Liczba błędów do popełnienia przy tego typu module była bardzo duża i nie wykluczalaliśmy
	  żadnego scenariusza. Upewniliśmy się, że:
	\begin{itemize}
	  \item {autorzy są podawani w losowej kolejności - poprzez sprawdzenie metody losującej numery autorów,
	  a także poprzez wypisywanie na ekran autorów w kolejnych batchach}
	  \item {moduł iteruje po tekstach poprawnie - to znaczy, czy kolejne sekwencje podawane do sieci to
	  kolejne litery danego autora - w tym celu odkodowywaliśmy z batcha wektory one-hot przy pomocy
	  specjalnie przygotowanego skryptu. Odkodowywaliśmy także oczekiwanie wyjście. Żeby wykluczyć ewentualne błędy,
	  teksty były odkodowywane wykorzystując alfabet poprzez który były kodowane.
	  Przykład dla jednego autora:
\begin{bash} 
AUTHOR 0) SEQUENCE: |my, my, i was forget|     TARGET: |t|
AUTHOR 0) SEQUENCE: |y, my, i was forgett|     TARGET: |i|
AUTHOR 0) SEQUENCE: |, my, i was forgetti|     TARGET: |n|
AUTHOR 0) SEQUENCE: | my, i was forgettin|     TARGET: |g|
AUTHOR 0) SEQUENCE: |my, i was forgetting|     TARGET: | |
AUTHOR 0) SEQUENCE: |y, i was forgetting |     TARGET: |a|
AUTHOR 0) SEQUENCE: |, i was forgetting a|     TARGET: |l|
AUTHOR 0) SEQUENCE: | i was forgetting al|     TARGET: |l|
AUTHOR 0) SEQUENCE: |i was forgetting all|     TARGET: | |
AUTHOR 0) SEQUENCE: | was forgetting all |     TARGET: |a|
AUTHOR 0) SEQUENCE: |was forgetting all a|     TARGET: |b|
AUTHOR 0) SEQUENCE: |as forgetting all ab|     TARGET: |o|
AUTHOR 0) SEQUENCE: |s forgetting all abo|     TARGET: |u|
\end{bash} }
	  \item {rozmiary macierzy z danymi wejściowymi - sprawdziliśmy czy wymiary macierzy z danymi wejściowymi jest zgodny
	  z dokumentacją modułu sieci neuronowej dostarczonej przez PyTorcha. W naszym przypadku były to
	  (liczba batchy) $\times$ (liczba sekwencji) $\times$ (rozmiar alfabetu) }
	\end{itemize}

\subsubsection{Sprawdzenie modułu sieci}
W skład sprawdzenia modułu sieci wchodziły następujące kroki:
	\begin{itemize}
	  \item {czy warstwy są poprawnie zainicjalizowane - w szczególności chodziło tutaj o inicjalizacje głowic,
	  których musiało być tyle ile autorów,}
	  \item {sprawdzenie metody forward - czy dane są poprawnie przekazywane do sieci rekurencyjnej, a następnie
	  z sieci rekurencyjnej do poszczególnych głowic,}
	  \item {czy do głowic przekazywany jest dobry krok czasowy - mieliśmy podejrzenie, że do głowic przekazywany jest przykładowo
	  pierwszy krok czasowy, a powinien być ostatni,}
	  \newpage
	  \item {badanie wyjścia z poszczególnych warstw - okazało się, że wartości zbiegają do pewnego wektora przez kilka pierwszych epok,
	  i potem już praktycznie dla każdej litery wszystkie elementy wektora wyjściowego oscylują blisko odpowiadającej wartości z  wektora,
	  do którego zbiegały. Okazało się to manifestacją błędu, który wykryliśmy w innym miejscu kodu i opisaliśmy kilka punktów dalej.}
	\end{itemize}

\subsubsection{Liczenie kosztu i propagacja wsteczna}
Liczenie kosztu jest u nas zaimplementowane nietypowo i polega na maskowaniu kosztów, które pochodzą od autorów
nienależących do danej głowicy.
\begin{python}
mask = (torch.tensor(authors_order) == head + 1).float()
softmax = self.softmax(outputs[head])
vector = self.loss(softmax, target)
vector = vector * mask
loss = torch.add(torch.sum(vector) / torch.sum(mask), loss)

\end{python}
Rzeczy, które sprawdziliśmy:
\begin{itemize}
	  \item {czy funkcja kosztu liczy się w dobrej osi,}
	  \item {czy maska tworzona jest poprawnie - to znaczy czy wygaszane są koszty właściwych autorów,}
	  \item {całkowicie zlikwidowaliśmy maskowanie i uczyliśmy tylko na jednym autorze w batchu, żeby być pewnym, że ten fragment
	  kodu nie jest problematyczny.}
\end{itemize}

\subsubsection{Uproszczony model w Kerasie}
Stworzyliśmy uproszczony model w bibliotece Keras 2.3.1 \cite{keras}, który uczył się przewidywać kolejne znaki na podstawie podanego tekstu.
Wybraliśmy Kerasa z racji na fakt, że bardzo szybko pisze się w nim mało skomplikowane modele.
Chcieliśmy się upewnić czy koncepcyjnie ma to szansę na powodzenie, z racji na to, że dane wejściowe w kodowaniu one-hot
są dosyć niespotykanym podejściem w tego typu problemach. Najczęściej proponowanym rozwiązaniem jest podawanie znaków jako klasy, następnie
przekazywanie jej do warstwy osadzenia (ang. embedding), która dopiero przekazuje swoje dane wyjściowe do sieci rekurencyjnej.
Sieć napisana w Kerasie trenowała się i miała po kilku epokach więcej niż $50\%$ skuteczności, jednak uczyła się
dużo wolniej od modelu z klasami i warstwą embedding. Nie rozwijaliśmy tego modelu dalej, gdyż chodziło tylko o sprawdzenie poprawności samej koncepcji.

\newpage
\subsection{Znalezione błędy}
Poważnym błędem jaki znaleźliśmy była inicjalizacja warstw liniowych.
Przed zmianą:
\begin{python}
self.linears = [nn.Linear(hidden_size, vocab_size) for i in range(authors_size)]

\end{python}
Po zmianie:
\begin{python}
self.linears = nn.ModuleList([nn.Linear(hidden_size, vocab_size) for i in range(authors_size)])

\end{python}

Lista warstw liniowych nie była widoczna dla modułu PyTorchowego (\texttt{module.nn}), ponieważ warstwy były przechowywane
w zwykłej liście, przez co gradienty warstw liniowych nie były zerowane pomiędzy iteracjami.

\begin{figure}[H]
	\centering
	\includegraphics[height=7cm]{./images/loss_decrease.png}
	\caption{Spadek kosztu na głowicy numer 1 na danych treningowych.}
	\label{fig:test5}
\end{figure}

Po poprawce sieć zaczęła się uczyć i na danych treningowych zaczęła spadać wartość funkcji kosztu. W efektcie jeśli
używaliśmy tekstów treningowych do testowania skuteczności, każda głowica faktycznie najlepiej przewidywała
znaki dla tekstu na którym się uczyła i szybko dokładność wynosiła blisko $100\%$. Jednak na danych testowych
skuteczność pozostawała bardzo niska, między $5\%$ a $15\%$. Nie mieliśmy czasu aby lepiej dobrać parametry uczenia.
Odpowiedzialny za złe rezultaty prawdopodobnie był problem opisany w sekcji 6.1.5, który objawiał 
się wzrastającą wartością kosztu po kilkunastu epokach uczenia.

Pozostałym elementom kodu nie udało nam się nic zarzucić. Na dalsze szukanie błędów brakło nam czasu.
Jednak wszystko wskazuje na to, że sieć uczy się poprawnie, a dalszy czas należałoby poświęcić na dobranie odpowiednich
parametrów.
