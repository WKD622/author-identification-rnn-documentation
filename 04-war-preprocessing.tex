\newpage
\section{Wybrane aspekty realizacji}

\subsection{Korpus tekstów}
Korpus tekstów wykorzystywany do trenowania sieci został przygotowany przez autorów konkursu PAN 2015 \cite{pan}.
W katalogu dla każdego języka znajdują się katalogi składające się z tekstów danego autora oraz jednego
tekstu nieznanego autorstwa. Oprócz tego dla każdego zestawu autorów dostarczany jest plik \texttt{truth.txt}.
Zawarta w nim jest informacja, czy dany autor napisał tekst nieznanego pochodzenia znajdujący się w katalogu.

\subsection{Preprocesing}
Preprocesing to proces przygotowywania danych wejściowych tak by nadawały się do szkolenia sieci.

W naszej pracy preprocesing dzieli się na dwa etapy:
\begin{enumerate}
	\item Redukcja alfabetu (mapowanie znaków)
	\item Zamiana zredukowanych tekstów na one-hot encoding
\end{enumerate}

Domyślnie dostępnymi językami w bibliotece są:
\languages 
 

\subsubsection{Redukcja alfabetu}
Alfabet definiujemy jako zbiór znaków występujących we wszystkich tekstach w zbiorze danych wejściowych. 
Redukcja alfabetu pozwala na zredukowanie złożności obliczeniowej oraz zmniejsza wpływ bardzo rzadko
występujących znaków na model języka. Pierwszym krok to normalizacja znaków. 
Przykładowo dla języka polskiego litera \texttt{ó} zostałaby zdekomponowana do litery o oraz znaku oznaczającego kreskę.
Następnie wykonywany jest szereg zdefiniowanych mapowań takich jak:
\begin{enumerate}
  \item zamiana każdej cyfry na cyfrę 7,
  \item znaki nie występujące w danym alfabecie są usuwane,
  \item wielkie litery zastępowane są odpowiadającym im małym literom oraz prefiksem,
  \item znaki interpunkcyjne sprowadzane do kanoniczej formy.
\end{enumerate}
\newpage
W celu redukcji alfabetu definiujemy pliki, w których przechowujemy przepisy mapowań, to znaczy
jaki znak mapujemy na jaki. Przykładowy fragment pliku do redukcji alfabetu języka
angielskiego znajduje się poniżej (został on znacznie skrócony wzlgędem oryginału żeby zachować lepszą
czytelność)

\begin{python}
charmap = {
    u'V': u'\xb9v',     
    u'K': u'\xb9k',         
    u'Q': u'\xb9q',        
    u'U': u'\xb9u',   
    u'_': '',             
    u':': u':',             
    u'[': u'(',           
    u'(': u'(',               
    u')': u')',              
    u']': u')',              
    u'}': u')',              
    u'{': u'(',                 
}
\end{python}

Tak przygotowany maper pozwala na zamianę wybranych znaków, które nie są kluczowe w procesie 
szkolenia sieci na wybrane inne znaki. Jeśli znak nie jest ujęty w maperze, nie jest zamieniany. 

\subsubsection{Zamiana tekstów na kodowanie one-hot encoding}
Teksty zamieniamy na tablice składająca się z wektorów w kodowaniu one-hot encoding. 
Aby tego dokonać potrzebny jest nam alfabet. Alfabet definiujemy w tym przypadku jako listę, której 
elementami są wszystkie znakami występujące w tekstach po redukcji alfabetu. Tak wygląda przykładowy fragment alfabetu dla tekstów
 w języku angielskim:
\begin{python}
alphabet = [
    ' ',
    'e',
    't',
    'o',
    'a',
    'n',
    'i',
    's',
    'h',
    'r',  # 10
    '\\n',
    'l',
    'd',
    'u',
]
\end{python}

Każdy znak zredukowanego pliku wejściowego zamieniany jest na wektor wykorzystując alfabet, 
a wektory 'umieszczane' są w tablicy i zapisywane do pliku. Przykład:

Załóżmy że nasz alfabet wygląda następująco:

\begin{python}
alphabet = [
    'a',  #0
    'b',  #1
    'c',  #2
    'd',  #3
 ]
\end{python} 
Jeśli zamienimy literę 'a' na wektor otrzymamy: 
 
\vspace{2mm}
$
\begin{bmatrix} 
1, & 0, & 0, & 0
\end{bmatrix} 
$
\vspace{2mm}

Ponieważ litera 'a' jest na pozycji 0 w alfabecie liczba 1 pojawiła się na pozycji 0 w wektorze.
Długość wektora wynosi 4 ponieważ tyle znaków znajduje się w alfabecie.

W ten sposób konwertowane są wszystkie znaki.
Każdy autor ma odrębną tablice, której elementami są wyżej wspomniane wektory umieszczane tam zgodnie 
z kolejnością ich występowania w tekście. 
Następnie następuje zapis do pliku, a później w procesie uczenia podział na batche.