\newpage
\section{Wybrane aspekty realizacji}

\subsection{Korpus tekstów}
Korpus tekstów wykorzystywany do trenowania sieci został przygotowany przez autorów konkursu PAN 2015 \cite{pan}.
W katalogu głównym znajdują się 4 katalogi, każdy dla innego języka (angielskiego, holenderskiego, greckiego oraz hiszpańskiego).
W obrębie katalogu jednego języka znajduje się między 100 a 500 katalogów autorów, każdy składa się z tekstów danego autora oraz jednego
tekstu nieznanego autorstwa. Oprócz tego dla każdego zestawu autorów dostarczany jest plik \texttt{truth.txt}.
Zawarta jest w nim informacja, czy dany autor napisał tekst nieznanego pochodzenia znajdujący się w jego katalogu.
Taką strukturę ma zbiór treningowy oraz testowy. Z racji na problemy techniczne z kodem uprościliśmy ten problem 
aby zminimalizować obszar, w którym może wystąpić błąd. Dlatego tak przygotowany zbiór dzieliliśmy na zbiór treningowy, który
składał się z tekstów znanych autorów oraz zbiór testowy, który składał się z tekstów nieznanego autorstwa. 
\newline Struktura korpusu tekstów konkursu PAN 2015:

\myspace
\dirtree{%
.1 spanish.
.2 SP001.
.3 known01.txt.
.3 unknown.txt.
.2 \ldots.
.2 SP100.
.3 known01.txt. 
.3 unknown.txt.
.2 truth.txt.
.1 greek.
.2 GR001.
.3 known01.txt.
.3 unknown.txt.
.2 \ldots.
.2 GR100.
.3 known01.txt.
.3 unknown.txt.
.2 truth.txt.
.1 english.
.2 EN001.
.3 known01.txt.
.3 unknown.txt.
.2 \ldots.
.2 EN100.
.3 known01.txt.
.3 unknown.txt.
.2 truth.txt.
.1 dutch.
.2 DU001.
.3 known01.txt.
.3 unknown.txt.
.2 \ldots.
.2 DU100.
.3 known01.txt.
.3 unknown.txt.
}
\myspace

\subsection{Preprocesing}
Preprocesing to proces przygotowywania danych wejściowych tak by nadawały się do szkolenia sieci.
W naszej pracy preprocesing podzielony jest na dwa etapy:
\begin{enumerate}
	\item Redukcja alfabetu (mapowanie znaków)
	\item Zamiana zredukowanych tekstów na one-hot encoding
\end{enumerate}

Domyślnie dostępnymi językami w bibliotece są:
\languages 
 

\subsubsection{Redukcja alfabetu}
Alfabet definiujemy jako zbiór znaków występujących we wszystkich tekstach w zbiorze danych wejściowych.
Redukcja następuje bez względu na to, czy mówimy o zbiorze testowym czy treningowym.
Redukcja alfabetu pozwala na zredukowanie złożności obliczeniowej oraz zmniejsza wpływ bardzo rzadko
występujących znaków na model języka. Pierwszym krok to normalizacja znaków. 
Przykładowo dla języka polskiego litera \texttt{ó} zostałaby zdekomponowana do litery \texttt{o} oraz znaku oznaczającego kreskę.
Następnie wykonywany jest szereg zdefiniowanych mapowań takich jak:
\begin{enumerate}
  \item każda cyfra zamieniana jest na cyfrę 7,
  \item znaki nie występujące w danym alfabecie są usuwane,
  \item wielkie litery zastępowane są odpowiadającym im małym literom oraz prefiksem,
  \item znaki interpunkcyjne sprowadzane do kanoniczej formy.
\end{enumerate}
\newpage
W celu redukcji alfabetu definiujemy pliki, w których przechowujemy sposób mapowania. Przykładowy fragment pliku do redukcji alfabetu języka
angielskiego znajduje się poniżej (został on znacznie skrócony wzlgędem oryginału żeby zachować lepszą
czytelność):

\begin{python}
charmap = {
    u'V': u'\xb9v',     
    u'K': u'\xb9k',         
    u'Q': u'\xb9q',        
    u'U': u'\xb9u',   
    u'_': '',             
    u':': u':',             
    u'[': u'(',           
    u'(': u'(',               
    u')': u')',              
    u']': u')',              
    u'}': u')',              
    u'{': u'(',                 
}
\end{python}

Tak przygotowane mapowanie pozwala na zamianę wybranych znaków, które nie są kluczowe w procesie 
szkolenia sieci na wybrane inne znaki. Jeśli znak nie jest ujęty w mapowaniu, nie jest zamieniany. 

\subsubsection{Zamiana tekstów na kodowanie one-hot}
Teksty zamieniamy na tablice składająca się z wektorów w kodowaniu one-hot encoding. 
Aby tego dokonać potrzebny jest nam alfabet. Alfabet definiujemy w tym przypadku jako listę, której 
elementami są wszystkie znakami występujące w tekstach po redukcji alfabetu. Tak wygląda przykładowy fragment alfabetu dla tekstów
 w języku angielskim:
\begin{python}
alphabet = [
    ' ',
    'e',
    't',
    'o',
    'a',
    'n',
    'i',
    's',
    'h',
    'r',  # 10
    '\\n',
    'l',
    'd',
    'u',
]
\end{python}

Każdy znak zredukowanego pliku wejściowego zamieniany jest na wektor wykorzystując alfabet, 
a wektory 'umieszczane' są w tablicy i zapisywane do pliku. Przykład:

Załóżmy że nasz alfabet wygląda następująco:

\begin{python}
alphabet = [
    'a',  #0
    'b',  #1
    'c',  #2
    'd',  #3
 ]
\end{python} 
Jeśli zamienimy literę 'a' na wektor otrzymamy: 
 
\vspace{2mm}
$
\begin{bmatrix} 
1, & 0, & 0, & 0
\end{bmatrix} 
$
\vspace{2mm}

Ponieważ litera 'a' jest na pozycji 0 w alfabecie liczba 1 pojawiła się na pozycji 0 w wektorze.
Długość wektora wynosi 4 ponieważ tyle znaków znajduje się w alfabecie.

W ten sposób konwertowane są wszystkie znaki.
Każdy autor ma odrębną tablice, której elementami są wyżej wspomniane wektory umieszczane tam zgodnie 
z kolejnością ich występowania w tekście. 
Następnie następuje zapis do pliku, a później w procesie uczenia podział na batche.